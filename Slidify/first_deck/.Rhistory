# iterate 10 times
for(i in 1:10){
# create sample from data with replacement
ss <- sample(1:dim(ozone)[1],replace=T)
# draw sample from the dataa and reorder rows based on ozone
ozone0 <- ozone[ss,]
ozone0 <- ozone0[order(ozone0$ozone),]
# fit loess function through data (similar to spline)
loess0 <- loess(temperature ~ ozone,data=ozone0,span=0.2)
# prediction from loess curve for the same values each time
ll[i,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
library(rattle)
library(rpart.plot)
library(plyr)
library(colorspace)
library(ggplot2)
library(caret)
library(kernlab)
library(stats)
library(MASS)
library(e1071)
library(ISLR)
library(Hmisc)
library(gridExtra)
library(RANN)
library(splines)
library(ElemStatLearn)
data(ozone,package="ElemStatLearn")
# reorder rows based on ozone variable
ozone <- ozone[order(ozone$ozone),]
# create empty matrix
ll <- matrix(NA,nrow=10,ncol=155)
# iterate 10 times
for(i in 1:10){
# create sample from data with replacement
ss <- sample(1:dim(ozone)[1],replace=T)
# draw sample from the dataa and reorder rows based on ozone
ozone0 <- ozone[ss,]
ozone0 <- ozone0[order(ozone0$ozone),]
# fit loess function through data (similar to spline)
loess0 <- loess(temperature ~ ozone,data=ozone0,span=0.2)
# prediction from loess curve for the same values each time
ll[i,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
# plot the data points
plot(ozone$ozone,ozone$temperature,pch=19,cex=0.5)
# plot each prediction model
for(i in 1:10){lines(1:155,ll[i,],col="grey",lwd=2)}
# plot the average in red
lines(1:155,apply(ll,2,mean),col="red",lwd=2)
data(iris)
# create train/test data sets
inTrain <- createDataPartition(y=iris$Species,p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
modFit <- train(Species~ .,data=training,method="rf",prox=TRUE)
# return the second tree (first 6 rows)
head(getTree(modFit$finalModel,k=2))
modFit
irisP <- classCenter(training[,c(3,4)], training$Species, modFit$finalModel$prox)
# convert irisP to data frame and add Species column
irisP <- as.data.frame(irisP); irisP$Species <- rownames(irisP)
# plot data points
p <- qplot(Petal.Width, Petal.Length, col=Species,data=training)
# add the cluster centers
p + geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species),size=5,shape=4,data=irisP)
head(getTree(modFit$finalModel,k=2))
pred <- predict(modFit,testing)
# logic value for whether or not the rf algorithm predicted correctly
testing$predRight <- pred==testing$Species
# tabulate results
table(pred,testing$Species)
# plot data points with the incorrect classification highlighted
qplot(Petal.Width,Petal.Length,colour=predRight,data=testing,main="newdata Predictions")
pred <- predict(modFit,testing)
# logic value for whether or not the rf algorithm predicted correctly
testing$predRight <- pred==testing$Species
# tabulate results
table(pred,testing$Species)
# plot data points with the incorrect classification highlighted
qplot(Petal.Width,Petal.Length,colour=predRight,data=testing,main="newdata Predictions")
data(iris)
# create train/test data sets
inTrain <- createDataPartition(y=iris$Species,p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
# apply random forest
modFit <- train(Species~ .,data=training,method="rf",prox=TRUE)
# return the second tree (first 6 rows)
head(getTree(modFit$finalModel,k=2))
# compute cluster centers
irisP <- classCenter(training[,c(3,4)], training$Species, modFit$finalModel$prox)
# convert irisP to data frame and add Species column
irisP <- as.data.frame(irisP); irisP$Species <- rownames(irisP)
# plot data points
p <- qplot(Petal.Width, Petal.Length, col=Species,data=training)
# add the cluster centers
p + geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species),size=5,shape=4,data=irisP)
# predict outcome for test data set using the random forest model
pred <- predict(modFit,testing)
# logic value for whether or not the rf algorithm predicted correctly
testing$predRight <- pred==testing$Species
# tabulate results
table(pred,testing$Species)
# plot data points with the incorrect classification highlighted
qplot(Petal.Width,Petal.Length,colour=predRight,data=testing,main="newdata Predictions")
data(Wage)
# remove log wage variable (we are trying to predict wage)
Wage <- subset(Wage,select=-c(logwage))
# create train/test data sets
inTrain <- createDataPartition(y=Wage$wage,p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
# run the gbm model
modFit <- train(wage ~ ., method="gbm",data=training,verbose=FALSE)
library(gbm)
data(Wage)
# remove log wage variable (we are trying to predict wage)
Wage <- subset(Wage,select=-c(logwage))
# create train/test data sets
inTrain <- createDataPartition(y=Wage$wage,p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
# run the gbm model
modFit <- train(wage ~ ., method="gbm",data=training,verbose=FALSE)
# print model summary
print(modFit)
qplot(predict(modFit,testing),wage,data=testing)
install.packages("AppliedPredictiveModeling")
install.packages("pgmm")
install.packages("rpart")
install.packages("rpart")
library(AppliedPredictiveModeling)
library(caret)
library(ElemStatLearn)
library(pgmm)
library(rpart)
data(segmentationOriginal)
head(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
training
training[3]
training[2]
list(training[2])
data(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
data(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
head(training)
head(training[2])
dim(training)
set.seed(125)
ModelFit<-rpart(Case~., data=training)
pred <- predict(ModelFit,testing)
pred
head(pred)
ModelFit<-rpart(Case~., data=training, method="class")
pred <- predict(ModelFit,testing)
pred
head(pred)
print(ModelFit)
data(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training)
set.seed(125)
modFit <- train(Case ~ .,method="rpart",data=training)
print(modFit$finalModel)
rattle::fancyRpartPlot(modFit$finalModel)
data(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training)
set.seed(125)
modFit <- train(Case ~ .,method="rpart",data=training)
print(modFit)
print(modFit$finalModel)
rattle::fancyRpartPlot(modFit$finalModel)
data(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training)
set.seed(125)
modFit <- train(Case ~ .,method="rpart",data=training)
# print the classification tree
print(modFit$finalModel)
# plot the classification tree
rattle::fancyRpartPlot(modFit$finalModel)
# predict on test values
predict(modFit,newdata=testing)
modFit
print(modFit)
rattle::fancyRpartPlot(modFit)
data(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training)
set.seed(125)
modFit <- train(Case ~ .,method="rpart",data=training)
# print the classification tree
print(modFit$finalModel)
# plot the classification tree
print(modFit)
rattle::fancyRpartPlot(modFit)
qplot(predict(modFit,testing),Case,data=testing)
names(segmentationOriginal)
data(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=.6 list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training)
set.seed(125)
data(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.6 list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training)
set.seed(125)
data(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.6, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training)
set.seed(125)
modFit <- train(Case ~ .,method="rpart",data=training)
# print the classification tree
print(modFit)
table(segmentationOriginal$Case)
data(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training)
set.seed(125)
qplot(segmentationOriginal$TotalIntench2, TotalIntench2$FiberWidthCh1, colour=FiberWidthCh1 $Case)
qplot(TotalIntench2, FiberWidthCh1, colour=Case, data=training)
qplot(TotalIntenCh2, FiberWidthCh1, colour=Case, data=training)
qplot(TotalIntenCh2, PerimStatusCh1, colour=Case, data=training)
qplot(FiberWidthCh1, PerimStatusCh1, colour=Case, data=training)
qplot(VarIntenCh4, PerimStatusCh1, colour=Case, data=training)
qplot(VarIntenCh4, TotalIntenCh2, colour=Case, data=training)
qplot(VarIntenCh4, FiberWidthCh1, colour=Case, data=training)
data(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training)
set.seed(125)
modFit <- train(Case ~ .,method="rpart",data=training)
# print the classification tree
print(modFit$finalModel)
head(segmentationOriginal$Case)
data(segmentationOriginal)
##inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.7, list=FALSE)
training <- segmentationOriginal[which(segmentationOriginal$Case=="Train"),]
testing <- segmentationOriginal[which(segmentationOriginal$Case=="Test"),]
dim(training)
set.seed(125)
modFit <- train(Case ~ .,method="rpart",data=training)
data(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case,list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training)
set.seed(125)
modFit <- train(Case ~ .,method="rpart",data=training)
print(modFit$finalModel)
rattle::fancyRpartPlot(modFit)
rattle::fancyRpartPlot(modFit$finalModel)
predict(modFit,testing)
names(segmentationOriginal)
head(segmentationOriginal$Cell)
head(segmentationOriginal$Class)
data<-data(segmentationOriginal)
data<-data(segmentationOriginal)
training <- data[which(data$Case=="Train"),]
testing <- data[which(data$Case=="Test"),]
dim(training)
set.seed(125)
data[which(data$Case=="Train"),]
names(data)
data(segmentationOriginal)
d<-segmentationOriginal
training <- d[which(d$Case=="Train"),]
testing <- d[which(d$Case=="Test"),]
dim(training)
set.seed(125)
modFit <- train(Class ~ .,method="rpart",data=training)
print(modFit$finalModel)
rattle::fancyRpartPlot(modFit$finalModel)
data(segmentationOriginal)
d<-segmentationOriginal
training <- d[which(d$Case=="Train"),]
testing <- d[which(d$Case=="Test"),]
dim(training)
set.seed(125)
modFit <- train(Class ~ .,method="rpart",data=training)
# print the classification tree
print(modFit$finalModel)
# plot the classification tree
rattle::fancyRpartPlot(modFit$finalModel)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
names(olive)
dim(olive)
data(olive)
data(olive)
names(olive)
dim(olive)
data(olive)
olive = olive[,-1]
d<-olive
inTrain <- createDataPartition(y=d$Area,p=0.7, list=FALSE)
training <- d[inTrain,]
testing <- d[-inTrain,]
dim(training); dim(testing)
modFit <- train(Area ~ .,method="rpart",data=training)
print(modFit$finalModel)
# plot the classification tree
rattle::fancyRpartPlot(modFit$finalModel)
predict(modFit,newdata=as.data.frame(t(colMeans(olive))))
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
names(SAheart)
set.seed(13234)
modFit <- train(chd ~ age+alcohol+obesity+tobacco+typea+ldl,method="glm",family="binomial",data=training)
set.seed(13234)
modFit <- train(chd ~ age+alcohol+obesity+tobacco+typea+ldl,method="glm",family="binomial",data=trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
misClass
missClass
missClass(trainSA,5)
missClass(trainSA,.31)
missClass(trainSA,.0001)
rattle::fancyRpartPlot(modFit$finalModel)
print(modFit$finalModel)
missClass(trainSA,testSA)
modFit
missClass(trainSA,231)
missClass(trainSA,800)
missClass(trainSA,56876513)
missClass(trainSA,.00000003)
missClass(4,5)
missClass(trainSA,0)
missClass(trainSA,0.5)
dim(trainSA)
dim(testSA)
missClass(testSA,0.5)
missClass(testSA,0)
231-205
26/231
231-204
27/231
missClass(testSA,0.4)
missClass(testSA,0.2)
missClass(testSA,500)
print(modFit$finalModel)
printcp(modFit)
modFit<-rpart(chd ~ age+alcohol+obesity+tobacco+typea+ldl,data=trainSA)
printcp(modFit)
summary(tree(chd ~ age+alcohol+obesity+tobacco+typea+ldl,data=trainSA))
install.packages("tree")
library(tree)
summary(tree(chd ~ age+alcohol+obesity+tobacco+typea+ldl,data=trainSA))
dim(trainSA)
missClass(231,40)
missClass(231,5)
missClass(trainSA,5)
missClass(trainSA,231)
missClass(trainSA,.43)
data(vowel.train)
data(vowel.test)
names(vowel.train)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
modFit <- train(y~ .,data=vowel.train,method="rf",prox=TRUE)
VarImp(modelFit, scale=FALSE)
varImp(modelFit, scale=FALSE)
data(vowel.train)
data(vowel.test)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
modFit <- train(y~ .,data=vowel.train,method="rf",prox=TRUE)
varImp(modelFit, scale=FALSE)
varImp(modFit, scale=FALSE)
data(vowel.train)
data(vowel.test)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
modFit <- train(y~ .,data=vowel.train,method="rf",prox=TRUE)
varImp(modFit, scale=FALSE)
varImp(modFit, scale=TRUE)
varImp(modFit, scale=FALSE)
data(segmentationOriginal)
d<-segmentationOriginal
training <- d[which(d$Case=="Train"),]
testing <- d[which(d$Case=="Test"),]
dim(training)
set.seed(125)
modFit <- train(Class ~ .,method="rpart",data=training)
print(modFit$finalModel)
# plot the classification tree
rattle::fancyRpartPlot(modFit$finalModel)
shiny::runApp('Training/DataScienceClass/DataProducts/Week1/Shiney-5')
shiny::runApp('Training/DataScienceClass/DataProducts/Week1/Shiney-4')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/Week1/App-4')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/Week1/Shiney-4')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
CMGR<-function(new,old,n) ((new/old)^(1/n))-1
CMGR(6,2,17)
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
paste("A", 1, "%")
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
shiny::runApp('Training/DataScienceClass/DataProducts/CourseProject')
library(devtools)
library(slidify)
library(knitr)
setwd("C:/Users/pame5815/Documents/Training/DataScienceClass/DataProducts/CourseProject/Slidify")
author("first_deck")
##make changes to document
slidify('index.Rmd')
browseURL('index.html')
library(devtools)
library(slidify)
library(knitr)
setwd("C:/Users/pame5815/Documents/Training/DataScienceClass/DataProducts/Week2/sample/project")
author("first_deck")
##make changes to document
slidify('index.Rmd')
browseURL('index.html')
library(devtools)
library(slidify)
library(knitr)
setwd("C:/Users/pame5815/Documents/Training/DataScienceClass/DataProducts/CourseProject/Slidify")
author("first_deck")
##make changes to document
slidify('index.Rmd')
browseURL('index.html')
install_version("stringr", version="0.6.2")
setwd("C:/Users/pame5815/Documents/Training/DataScienceClass/DataProducts/CourseProject/Slidify")
author("first_deck")
##make changes to document
slidify('index.Rmd')
browseURL('index.html')
setwd("C:/Users/pame5815/Documents/Training/DataScienceClass/DataProducts/CourseProject/Slidify")
author("first_deck")
##make changes to document
slidify('index.Rmd')
browseURL('index.html')
setwd("C:/Users/pame5815/Documents/Training/DataScienceClass/DataProducts/CourseProject/Slidify")
author("first_deck")
##make changes to document
slidify('index.Rmd')
browseURL('index.html')
setwd("C:/Users/pame5815/Documents/Training/DataScienceClass/DataProducts/CourseProject/Slidify")
author("first_deck")
##make changes to document
slidify('index.Rmd')
browseURL('index.html')
